import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from sqlalchemy import create_engine
from datetime import datetime
import logging

# Äá»c biáº¿n mÃ´i trÆ°á»ng
BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")

# Thiáº¿t láº­p logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Káº¿t ná»‘i PostgreSQL
engine = create_engine(DATABASE_URL)

# HÃ m Ä‘á»c dá»¯ liá»‡u lá»‹ch sá»­
def load_data():
    try:
        df = pd.read_sql("SELECT * FROM history ORDER BY created_at DESC LIMIT 100", engine)
        return df
    except Exception as e:
        logger.error(f"Lá»—i táº£i dá»¯ liá»‡u: {e}")
        return pd.DataFrame()

# HÃ m lÆ°u káº¿t quáº£ vÃ o DB
def save_result(real, predicted):
    try:
        query = f"""
            INSERT INTO history (real_result, predicted_result, created_at)
            VALUES ('{real}', '{predicted}', '{datetime.now()}')
        """
        with engine.connect() as conn:
            conn.execute(query)
    except Exception as e:
        logger.error(f"Lá»—i lÆ°u dá»¯ liá»‡u: {e}")

# HÃ m xá»­ lÃ½ dá»± Ä‘oÃ¡n káº¿t quáº£ tiáº¿p theo
def extract_features(results):
    features = []
    for r in results:
        total = sum(map(int, r.split("-")))
        is_even = total % 2 == 0
        is_tai = total > 10
        is_bao = len(set(r.split("-"))) == 1
        features.append([total, int(is_even), int(is_tai), int(is_bao)])
    return np.array(features)

# CÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c
def predict_with_models(X):
    rf = RandomForestClassifier()
    xgb = XGBClassifier()
    mlp = MLPClassifier()
    lstm_model = Sequential([
        LSTM(32, input_shape=(X.shape[1], 1)),
        Dense(4, activation='softmax')
    ])
    lstm_model.compile(loss='categorical_crossentropy', optimizer='adam')

    # Táº¡o nhÃ£n giáº£
    y = [random.choice(["TÃ i", "Xá»‰u", "Cháºµn", "Láº»"]) for _ in range(len(X))]

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
    rf.fit(X, y)
    xgb.fit(X, y)
    mlp.fit(X, y)
    X_lstm = X.reshape((X.shape[0], X.shape[1], 1))
    y_lstm = tf.keras.utils.to_categorical([["TÃ i", "Xá»‰u", "Cháºµn", "Láº»"].index(label) for label in y], num_classes=4)
    lstm_model.fit(X_lstm, y_lstm, epochs=5, verbose=0)

    # Dá»± Ä‘oÃ¡n vá»›i máº«u má»›i nháº¥t
    last_sample = X[-1].reshape(1, -1)
    preds = [
        rf.predict(last_sample)[0],
        xgb.predict(last_sample)[0],
        mlp.predict(last_sample)[0],
        ["TÃ i", "Xá»‰u", "Cháºµn", "Láº»"][np.argmax(lstm_model.predict(last_sample.reshape((1, X.shape[1], 1)), verbose=0))]
    ]
    return preds

# Tá»•ng há»£p káº¿t quáº£
def voting(preds):
    return max(set(preds), key=preds.count)

# Logic mÃ´ phá»ng con ngÆ°á»i
def logic_suy_luan(recent):
    totals = [sum(map(int, r.split("-"))) for r in recent]
    cháºµn_láº» = ["Cháºµn" if t % 2 == 0 else "Láº»" for t in totals]
    tai_xiu = ["TÃ i" if t > 10 else "Xá»‰u" for t in totals]
    bao = [1 if r.split("-")[0] == r.split("-")[1] == r.split("-")[2] else 0 for r in recent]

    # Dá»± Ä‘oÃ¡n náº¿u cÃ³ 3 láº§n liÃªn tiáº¿p giá»‘ng nhau
    if len(set(cháºµn_láº»[-3:])) == 1:
        du_doan_le = "Cháºµn" if cháºµn_láº»[-1] == "Láº»" else "Láº»"
    else:
        du_doan_le = cháºµn_láº»[-1]

    if len(set(tai_xiu[-3:])) == 1:
        du_doan_tx = "TÃ i" if tai_xiu[-1] == "Xá»‰u" else "Xá»‰u"
    else:
        du_doan_tx = tai_xiu[-1]

    is_bao = any(bao[-5:])
    return du_doan_tx, du_doan_le, is_bao

# Gá»­i pháº£n há»“i
async def handle_result(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    if not text.count("-") == 2:
        await update.message.reply_text("âš ï¸ Vui lÃ²ng nháº­p káº¿t quáº£ theo Ä‘á»‹nh dáº¡ng: 1-3-6")
        return

    real_result = text
    df = load_data()
    history = df["real_result"].tolist()[-20:] if not df.empty else []
    history.append(real_result)

    X = extract_features(history)
    preds = predict_with_models(X)
    final_vote = voting(preds)

    du_doan_tx, du_doan_le, bao = logic_suy_luan(history)
    save_result(real_result, f"{du_doan_tx}-{du_doan_le}")

    message = f"âœ… ÄÃ£ nháº­n káº¿t quáº£: `{real_result}`\n\n"
    message += f"ğŸ”® Dá»± Ä‘oÃ¡n phiÃªn tiáº¿p theo:\n"
    message += f"- {du_doan_tx} - {du_doan_le}\n"
    message += f"- Dáº£i Ä‘iá»ƒm nÃªn Ä‘Ã¡nh: {'11â€“17' if du_doan_tx == 'TÃ i' else '4â€“10'}\n"
    if bao:
        message += "âš ï¸ *Cáº£nh bÃ¡o: CÃ³ kháº£ nÄƒng 'BÃ£o'!*\n"
    message += f"\nğŸ“Š Tá»•ng phiÃªn Ä‘Ã£ lÆ°u: {len(df)} | ÄÃºng: ? | Sai: ?"

    await update.message.reply_text(message, parse_mode="Markdown")

# Lá»‡nh báº¯t Ä‘áº§u
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ‘‹ ChÃ o báº¡n! Gá»­i káº¿t quáº£ TÃ i Xá»‰u (vÃ­ dá»¥: `2-5-6`) Ä‘á»ƒ nháº­n dá»± Ä‘oÃ¡n phiÃªn tiáº¿p theo.")

# Khá»Ÿi táº¡o bot
def main():
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_result))
    print("Bot Ä‘ang cháº¡y...")
    app.run_polling()

if __name__ == "__main__":
    main()
