import os
import logging
import re
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from joblib import dump, load
import psycopg2
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from datetime import datetime, timedelta
import threading
from flask import Flask

# ==== Flask giá»¯ port trÃ¡nh sleep ====
def start_flask():
    app = Flask(__name__)

    @app.route('/')
    def home():
        return "Bot is alive!", 200

    @app.route('/healthz')
    def health():
        return "OK", 200

    app.run(host='0.0.0.0', port=10000)

threading.Thread(target=start_flask, daemon=True).start()
# ====================================

BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
MODEL_PATH = os.getenv("MODEL_PATH", "/tmp/sicbo_model.joblib")
BAO_MODEL_PATH = os.getenv("BAO_MODEL_PATH", "/tmp/bao_model.joblib")
TOTAL_MODEL_PATH = os.getenv("TOTAL_MODEL_PATH", "/tmp/total_model.joblib")

MIN_ACCURACY = 0.5
WINDOW_SIZE = 40
FEATURE_WINDOW = 3  # Sá»‘ phiÃªn gáº§n nháº¥t dÃ¹ng lÃ m feature

logging.basicConfig(level=logging.INFO)

def get_db_conn():
    return psycopg2.connect(DATABASE_URL)

def create_table():
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS history (
                    id SERIAL PRIMARY KEY,
                    input TEXT,
                    prediction TEXT,
                    actual TEXT,
                    created_at TIMESTAMP DEFAULT NOW()
                )
            """)
            conn.commit()

def insert_to_db(numbers, prediction, actual=None):
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO history (input, prediction, actual) VALUES (%s, %s, %s)",
                (numbers, prediction, actual)
            )
            conn.commit()

def fetch_history(limit=500, with_actual=True):
    with get_db_conn() as conn:
        query = "SELECT id, input, prediction, actual, created_at FROM history"
        if with_actual:
            query += " WHERE actual IS NOT NULL"
        query += " ORDER BY id DESC LIMIT %s"
        df = pd.read_sql(query, conn, params=(limit,))
    return df

def extract_features(nums):
    features = []
    features.extend(nums)  # 3 sá»‘ gá»‘c
    features.append(sum(nums))
    features.append(max(nums))
    features.append(min(nums))
    features.append(np.std(nums))
    features.append(np.mean(nums))
    features.append(1 if len(set(nums)) == 1 else 0)  # bÃ£o
    features.append(1 if sum(nums) % 2 == 0 else 0)   # cháºµn láº»
    features.append(1 if sum(nums) >= 11 else 0)      # tÃ i/xá»‰u
    return features

def get_window_features(history_inputs):
    features = []
    for nums in history_inputs:
        features += extract_features(nums)
    # Fill 0 náº¿u thiáº¿u data
    for _ in range(FEATURE_WINDOW - len(history_inputs)):
        features += [0] * 10
    return features

def label_func(nums):
    total = sum(nums)
    return "TÃ i" if total >= 11 else "Xá»‰u"

def is_bao(nums):
    return int(len(set(nums)) == 1)

def train_and_save_model():
    df = fetch_history(2000)
    if df.empty:
        return None
    df = df[df["actual"].notnull()]
    if len(df) < 10:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        y.append(df.iloc[i]["actual"])
    models = [
        ("rf", RandomForestClassifier(n_estimators=100)),
        ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
        ("mlp", MLPClassifier(max_iter=2000)),
        ("lr", LogisticRegression(max_iter=1000))
    ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def load_model():
    if os.path.exists(MODEL_PATH):
        return load(MODEL_PATH)
    return train_and_save_model()

def predict_with_model(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    return model.predict(X)[0], features

def detect_algo_change():
    df = fetch_history(WINDOW_SIZE)
    if len(df) < WINDOW_SIZE:
        return False
    acc = sum(df['prediction'] == df['actual']) / WINDOW_SIZE
    return acc < MIN_ACCURACY

def train_with_recent_data(n=100):
    df = fetch_history(n)
    df = df[df["actual"].notnull()]
    if len(df) < 10:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        y.append(df.iloc[i]["actual"])
    models = [
        ("rf", RandomForestClassifier(n_estimators=100)),
        ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
        ("mlp", MLPClassifier(max_iter=2000)),
        ("lr", LogisticRegression(max_iter=1000))
    ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def train_bao_model():
    df = fetch_history(2000)
    if df.empty or len(df) < 20:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        label = is_bao([int(x) for x in df.iloc[i]["input"].split()])
        y.append(label)
    model = RandomForestClassifier(n_estimators=50)
    model.fit(X, y)
    dump(model, BAO_MODEL_PATH)
    return model

def load_bao_model():
    if os.path.exists(BAO_MODEL_PATH):
        return load(BAO_MODEL_PATH)
    return train_bao_model()

def predict_bao_prob(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    prob = model.predict_proba(X)[0][1]
    return prob

# ====== Model multi-class dá»± Ä‘oÃ¡n tá»•ng ======
def train_total_model():
    df = fetch_history(2000)
    if df.empty or len(df) < 50:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0: continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        label = sum([int(x) for x in df.iloc[i]["input"].split()])
        y.append(label)
    model = RandomForestClassifier(n_estimators=80)
    model.fit(X, y)
    dump(model, TOTAL_MODEL_PATH)
    return model

def load_total_model():
    if os.path.exists(TOTAL_MODEL_PATH):
        return load(TOTAL_MODEL_PATH)
    return train_total_model()

def predict_total_prob(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    probs = model.predict_proba(X)[0]
    classes = model.classes_
    prob_dict = {cls: prob for cls, prob in zip(classes, probs)}
    return prob_dict

def suggest_best_totals(prob_dict, predict_label, parity=None, top_n=3):
    if predict_label == "TÃ i":
        candidate_totals = [i for i in range(11, 18)]
    else:
        candidate_totals = [i for i in range(4, 11)]
    if parity == "Cháºµn":
        candidate_totals = [i for i in candidate_totals if i % 2 == 0]
    elif parity == "Láº»":
        candidate_totals = [i for i in candidate_totals if i % 2 == 1]
    ranked = sorted(candidate_totals, key=lambda x: prob_dict.get(x, 0), reverse=True)
    return ranked[:top_n]
# ===========================================

def get_last_play_time():
    df = fetch_history(1, with_actual=False)
    if df.empty:
        return None
    return df["created_at"].iloc[0]

def time_diff_message(last_time):
    if last_time is None:
        return ""
    now = datetime.now(last_time.tzinfo)
    diff = now - last_time
    if diff > timedelta(hours=4):
        return ("âš ï¸ ÄÃ£ lÃ¢u báº¡n chÆ°a nháº­p káº¿t quáº£ thá»±c táº¿ vÃ o bot. Káº¿t quáº£ dá»± Ä‘oÃ¡n chá»‰ mang tÃ­nh tham kháº£o.")
    return ""

def generate_response(prediction, input_text, stats, time_msg, explain_msg="", bao_warn="", range_msg=""):
    nums = list(map(int, input_text.split()))
    total = sum(nums)
    tai_xiu = "TÃ i" if total >= 11 else "Xá»‰u"
    chan_le = "Cháºµn" if total % 2 == 0 else "Láº»"
    bao = "ğŸ² BÃƒO! Ba sá»‘ giá»‘ng nhau!" if len(set(nums)) == 1 else ""
    response = (
        f"ğŸ¯ {prediction}\n"
        f"ğŸ”¢ Tá»•ng: {total} ({tai_xiu} - {chan_le})\n"
        f"{bao}\n"
        f"{explain_msg}\n"
        f"{bao_warn}\n"
        f"{range_msg}\n"
        f"âœ”ï¸ ÄÃºng: {stats['correct']} | âŒ Sai: {stats['wrong']} | ğŸ¯ {stats['accuracy']}%"
    )
    if time_msg:
        response += f"\n{time_msg}"
    return response.strip()

def calculate_stats():
    df = fetch_history(50)
    correct = sum(df['prediction'] == df['actual'])
    total = len(df)
    wrong = total - correct
    acc = round(correct / total * 100, 2) if total > 0 else 0
    return {"correct": correct, "wrong": wrong, "accuracy": acc}

def explain_prediction(features, input_data, prev_inputs):
    last_sum = sum(input_data)
    if last_sum >= 11:
        xu_huong = "Tá»•ng cao"
    else:
        xu_huong = "Tá»•ng tháº¥p"
    msg = f"ğŸ“ˆ {xu_huong}"
    if prev_inputs:
        prev_tai = sum(1 for nums in prev_inputs if sum(nums) >= 11)
        if prev_tai > len(prev_inputs)//2:
            msg += ", gáº§n Ä‘Ã¢y Ä‘a pháº§n ra TÃ i."
        else:
            msg += ", gáº§n Ä‘Ã¢y Ä‘a pháº§n ra Xá»‰u."
    return msg

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ¤– Gá»­i 3 sá»‘ káº¿t quáº£ gáº§n nháº¥t Ä‘á»ƒ nháº­n dá»± Ä‘oÃ¡n (vÃ­ dá»¥: 456 hoáº·c 4 5 6). GÃµ /backup Ä‘á»ƒ xuáº¥t lá»‹ch sá»­ ra file."
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()

    # Check nháº­p nháº§m, nháº­p láº·p (so vá»›i phiÃªn trÆ°á»›c)
    df_hist_check = fetch_history(1, with_actual=False)
    if df_hist_check.shape[0] > 0:
        last_input_str = df_hist_check.iloc[0]["input"]
        # Chuáº©n hÃ³a input hiá»‡n táº¡i vá» dáº¡ng 3 sá»‘ cÃ¡ch nhau
        if re.match(r"^\d{3}$", text):
            this_input = f"{text[0]} {text[1]} {text[2]}"
        elif re.match(r"^\d+ \d+ \d+$", text):
            this_input = text
        else:
            this_input = ""
        if last_input_str == this_input:
            await update.message.reply_text("âš ï¸ Báº¡n vá»«a nháº­p káº¿t quáº£ nÃ y á»Ÿ phiÃªn trÆ°á»›c. Náº¿u nháº­p nháº§m, gá»­i láº¡i Ä‘Ãºng káº¿t quáº£ má»›i!")
            return

    # Chuáº©n hÃ³a input: '123' hoáº·c '1 2 3'
    if re.match(r"^\d{3}$", text):
        numbers = [int(x) for x in text]
        input_str = f"{numbers[0]} {numbers[1]} {numbers[2]}"
    elif re.match(r"^\d+ \d+ \d+$", text):
        numbers = [int(x) for x in text.split()]
        input_str = text
    else:
        await update.message.reply_text("âš ï¸ Vui lÃ²ng nháº­p 3 sá»‘ liá»n nhau (VD: 345) hoáº·c 3 sá»‘ cÃ¡ch nhau báº±ng dáº¥u cÃ¡ch (VD: 3 4 5).")
        return

    # GÃ¡n nhÃ£n thá»±c táº¿ cho lÆ°á»£t chÆ¡i trÆ°á»›c Ä‘Ã³ (náº¿u cÃ³)
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT id, input FROM history WHERE actual IS NULL ORDER BY id DESC LIMIT 1")
            last_entry = cur.fetchone()
    if last_entry:
        last_id, last_input = last_entry
        actual_label = label_func(numbers)
        with get_db_conn() as conn2:
            with conn2.cursor() as cur2:
                cur2.execute("UPDATE history SET actual = %s WHERE id = %s", (actual_label, last_id))
                conn2.commit()
        train_and_save_model()
        train_bao_model()
        train_total_model()

    # PhÃ¡t hiá»‡n Ä‘á»•i thuáº­t toÃ¡n
    algo_changed = detect_algo_change()
    if algo_changed:
        train_with_recent_data(WINDOW_SIZE * 2)
        train_bao_model()
        train_total_model()
        await update.message.reply_text(
            f"âš ï¸ BOT phÃ¡t hiá»‡n tá»‰ lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng giáº£m máº¡nh! Game cÃ³ thá»ƒ Ä‘Ã£ Ä‘á»•i thuáº­t toÃ¡n. BOT sáº½ tá»± Ä‘á»™ng há»c láº¡i sÃ³ng má»›i."
        )

    # Láº¥y cÃ¡c phiÃªn trÆ°á»›c cho feature chuá»—i
    df_hist = fetch_history(FEATURE_WINDOW-1, with_actual=False)
    prev_inputs = []
    if not df_hist.empty:
        prev_inputs = [[int(n) for n in s.split()] for s in reversed(df_hist["input"].tolist())]

    model = load_model()
    bao_model = load_bao_model()
    model_total = load_total_model()
    input_data = numbers
    if model is not None:
        prediction, features = predict_with_model(model, input_data, prev_inputs)
    else:
        prediction = label_func(input_data)
        features = extract_features(input_data)

    insert_to_db(input_str, prediction, actual=None)
    stats = calculate_stats()
    time_msg = time_diff_message(get_last_play_time())
    explain_msg = explain_prediction(features, input_data, prev_inputs)

    # Dá»± Ä‘oÃ¡n "bÃ£o" phiÃªn tiáº¿p theo: chá»‰ cáº£nh bÃ¡o náº¿u phiÃªn hiá»‡n táº¡i KHÃ”NG pháº£i bÃ£o
    bao_warn = ""
    if bao_model and len(set(input_data)) != 1:
        bao_prob = predict_bao_prob(bao_model, input_data, prev_inputs)
        if bao_prob > 0.08:
            bao_warn = f"âš¡ï¸ Dá»± bÃ¡o: PhiÃªn tiáº¿p theo cÃ³ kháº£ nÄƒng xuáº¥t hiá»‡n BÃƒO báº¥t thÆ°á»ng! (XÃ¡c suáº¥t ~{bao_prob:.1%})"

    # Äá» xuáº¥t dáº£i tá»•ng nÃªn Ä‘Ã¡nh (báº±ng model xÃ¡c suáº¥t tá»•ng)
    chan_le = "Cháºµn" if sum(input_data) % 2 == 0 else "Láº»"
    range_msg = ""
    if model_total is not None:
        prob_dict = predict_total_prob(model_total, input_data, prev_inputs)
        best_totals = suggest_best_totals(prob_dict, prediction, parity=chan_le)
        if best_totals:
            range_msg = f"ğŸ¯ Dáº£i tá»•ng {prediction.lower()} nÃªn Ä‘Ã¡nh ({chan_le.lower()}): " + ", ".join(str(t) for t in best_totals)

    response = generate_response(prediction, input_str, stats, time_msg, explain_msg, bao_warn, range_msg)
    if stats['correct'] + stats['wrong'] < 15:
        response += "\nâš ï¸ Dá»¯ liá»‡u cÃ²n Ã­t, chá»‰ nÃªn tham kháº£o!"
    await update.message.reply_text(response)

async def backup(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000, with_actual=False)
    if df.empty:
        await update.message.reply_text("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ backup.")
        return
    now_str = datetime.now().strftime("%Y-%m-%d_%H-%M")
    path = f"/tmp/sicbo_history_backup_{now_str}.csv"
    df.to_csv(path, index=False)
    await update.message.reply_document(document=open(path, "rb"), filename=f"sicbo_history_backup_{now_str}.csv")

def main():
    create_table()
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("backup", backup))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
