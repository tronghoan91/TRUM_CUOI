import os
import logging
import re
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from joblib import dump, load
import psycopg2
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from datetime import datetime
import threading
from flask import Flask
import asyncio

# ==== Flask giá»¯ port trÃ¡nh sleep ====
def start_flask():
    app = Flask(__name__)

    @app.route('/')
    def home():
        return "Bot is alive!", 200

    @app.route('/healthz')
    def health():
        return "OK", 200

    app.run(host='0.0.0.0', port=10000)

threading.Thread(target=start_flask, daemon=True).start()
# ====================================

BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
MODEL_PATH = os.getenv("MODEL_PATH", "/tmp/sicbo_model.joblib")
BAO_MODEL_PATH = os.getenv("BAO_MODEL_PATH", "/tmp/bao_model.joblib")
TOTAL_MODEL_PATH = os.getenv("TOTAL_MODEL_PATH", "/tmp/total_model.joblib")

MIN_ACCURACY = 0.5
WINDOW_SIZE = 40
FEATURE_WINDOW = 3  # Sá»‘ phiÃªn gáº§n nháº¥t dÃ¹ng lÃ m feature

# --- Tá»‘i Æ°u tá»‘c Ä‘á»™ retrain ---
RETRAIN_EVERY_N = 10
retrain_counter = 0

logging.basicConfig(level=logging.INFO)

def get_db_conn():
    return psycopg2.connect(DATABASE_URL)

def create_table():
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            # Táº¡o báº£ng náº¿u chÆ°a cÃ³
            cur.execute("""
                CREATE TABLE IF NOT EXISTS history (
                    id SERIAL PRIMARY KEY,
                    input TEXT,
                    created_at TIMESTAMP DEFAULT NOW()
                )
            """)
            # ThÃªm cá»™t 'prediction' náº¿u chÆ°a cÃ³
            cur.execute("""
                DO $$
                BEGIN
                    IF NOT EXISTS (
                        SELECT 1 FROM information_schema.columns 
                        WHERE table_name='history' AND column_name='prediction'
                    ) THEN
                        ALTER TABLE history ADD COLUMN prediction TEXT;
                    END IF;
                END$$;
            """)
            # ThÃªm cá»™t 'actual' náº¿u chÆ°a cÃ³
            cur.execute("""
                DO $$
                BEGIN
                    IF NOT EXISTS (
                        SELECT 1 FROM information_schema.columns 
                        WHERE table_name='history' AND column_name='actual'
                    ) THEN
                        ALTER TABLE history ADD COLUMN actual TEXT;
                    END IF;
                END$$;
            """)
            conn.commit()

def insert_to_db(numbers, prediction, actual=None):
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO history (input, prediction, actual) VALUES (%s, %s, %s)",
                (numbers, prediction, actual)
            )
            conn.commit()

def fetch_history(limit=500, with_actual=True):
    with get_db_conn() as conn:
        query = "SELECT id, input, prediction, actual, created_at FROM history"
        if with_actual:
            query += " WHERE actual IS NOT NULL"
        query += " ORDER BY id DESC LIMIT %s"
        df = pd.read_sql(query, conn, params=(limit,))
    return df

def extract_features(nums):
    features = []
    features.extend(nums)  # 3 sá»‘ gá»‘c
    features.append(sum(nums))
    features.append(max(nums))
    features.append(min(nums))
    features.append(np.std(nums))
    features.append(np.mean(nums))
    features.append(1 if len(set(nums)) == 1 else 0)  # bÃ£o
    features.append(1 if sum(nums) % 2 == 0 else 0)   # cháºµn láº»
    features.append(1 if sum(nums) >= 11 else 0)      # tÃ i/xá»‰u
    # Feature bá»• sung:
    features.append(nums[0] + nums[1])  # Tá»•ng 2 sá»‘ Ä‘áº§u
    features.append(nums[1] + nums[2])  # Tá»•ng 2 sá»‘ cuá»‘i
    features.append(abs(nums[0] - nums[2]))  # Äá»™ lá»‡ch Ä‘áº§u-cuá»‘i
    return features

def get_window_features(history_inputs):
    features = []
    for nums in history_inputs:
        features += extract_features(nums)
    # Fill 0 náº¿u thiáº¿u data
    for _ in range(FEATURE_WINDOW - len(history_inputs)):
        features += [0] * len(extract_features([0,0,0]))
    return features

def label_func(nums):
    total = sum(nums)
    return "TÃ i" if total >= 11 else "Xá»‰u"

def is_bao(nums):
    return int(len(set(nums)) == 1)

def get_total_history_count():
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT COUNT(*) FROM history WHERE actual IS NOT NULL")
            return cur.fetchone()[0]

def train_and_save_model():
    total = get_total_history_count()
    df = fetch_history(5000)
    if df.empty:
        return None
    df = df[df["actual"].notnull()]
    if len(df) < 30:
        print("Not enough data to train model. Need at least 30 rows.")
        return None

    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        y.append(df.iloc[i]["actual"])

    # DÆ°á»›i 200 phiÃªn chá»‰ dÃ¹ng 3 model máº¡nh nháº¥t, trÃªn 200 dÃ¹ng Ä‘á»§ 6 model
    if total < 200:
        models = [
            ("rf", RandomForestClassifier(n_estimators=100)),
            ("xgb", XGBoostClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
            ("lr", LogisticRegression(max_iter=1000))
        ]
    else:
        models = [
            ("rf", RandomForestClassifier(n_estimators=100)),
            ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
            ("lgb", LGBMClassifier(n_estimators=100)),
            ("cat", CatBoostClassifier(verbose=0, iterations=100)),
            ("mlp", MLPClassifier(max_iter=2000)),
            ("lr", LogisticRegression(max_iter=1000))
        ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def load_model():
    if os.path.exists(MODEL_PATH):
        return load(MODEL_PATH)
    return train_and_save_model()

def predict_with_model(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    return model.predict(X)[0], features

def detect_algo_change():
    df = fetch_history(WINDOW_SIZE)
    if len(df) < WINDOW_SIZE:
        return False
    acc = sum(df['prediction'] == df['actual']) / WINDOW_SIZE
    return acc < MIN_ACCURACY

def train_with_recent_data(n=100):
    df = fetch_history(n)
    df = df[df["actual"].notnull()]
    if len(df) < 30:
        print("Not enough data for LightGBM!")
        return None
    total = get_total_history_count()
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        y.append(df.iloc[i]["actual"])
    if total < 200:
        models = [
            ("rf", RandomForestClassifier(n_estimators=100)),
            ("xgb", XGBoostClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
            ("lr", LogisticRegression(max_iter=1000))
        ]
    else:
        models = [
            ("rf", RandomForestClassifier(n_estimators=100)),
            ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
            ("lgb", LGBMClassifier(n_estimators=100)),
            ("cat", CatBoostClassifier(verbose=0, iterations=100)),
            ("mlp", MLPClassifier(max_iter=2000)),
            ("lr", LogisticRegression(max_iter=1000))
        ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def train_bao_model():
    df = fetch_history(2000)
    if df.empty or len(df) < 30:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0:
                continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        label = is_bao([int(x) for x in df.iloc[i]["input"].split()])
        y.append(label)
    model = RandomForestClassifier(n_estimators=50)
    model.fit(X, y)
    dump(model, BAO_MODEL_PATH)
    return model

def load_bao_model():
    if os.path.exists(BAO_MODEL_PATH):
        return load(BAO_MODEL_PATH)
    return train_bao_model()

def predict_bao_prob(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    proba = model.predict_proba(X)[0]
    classes = model.classes_
    if len(classes) == 2:
        class_idx_1 = np.where(classes == 1)[0][0]
        return proba[class_idx_1]
    elif len(classes) == 1:
        return 1.0 if classes[0] == 1 else 0.0
    else:
        return 0.0

def train_total_model():
    df = fetch_history(2000)
    if df.empty or len(df) < 50:
        return None
    X, y = [], []
    for i in range(len(df)):
        history_inputs = []
        for j in range(FEATURE_WINDOW):
            if i-j < 0: continue
            nums = [int(x) for x in df.iloc[i-j]["input"].split()]
            history_inputs.insert(0, nums)
        X.append(get_window_features(history_inputs))
        label = sum([int(x) for x in df.iloc[i]["input"].split()])
        y.append(label)
    model = RandomForestClassifier(n_estimators=80)
    model.fit(X, y)
    dump(model, TOTAL_MODEL_PATH)
    return model

def load_total_model():
    if os.path.exists(TOTAL_MODEL_PATH):
        return load(TOTAL_MODEL_PATH)
    return train_total_model()

def predict_total_prob(model, input_data, prev_inputs):
    history_inputs = prev_inputs[-(FEATURE_WINDOW-1):] + [input_data]
    features = get_window_features(history_inputs)
    X = np.array([features])
    probs = model.predict_proba(X)[0]
    classes = model.classes_
    prob_dict = {cls: prob for cls, prob in zip(classes, probs)}
    return prob_dict

def suggest_best_totals_any(prob_dict, top_n=3):
    ranked = sorted(prob_dict.keys(), key=lambda x: prob_dict[x], reverse=True)
    return ranked[:top_n]

def get_streak_stats(df, n=5):
    results = (df['prediction'] == df['actual']).tolist()
    if not results:
        return 0, 0, ''
    streak = 1
    last = results[0]
    for res in results[1:]:
        if res == last:
            streak += 1
        else:
            break
    return streak, last, "tháº¯ng" if last else "thua"

def get_trend_msg(stats, streak, last, trend, bao_warn):
    if stats['accuracy'] >= 75:
        msg = "ðŸ”¥ SÃ³ng Ä‘ang ráº¥t Ä‘áº¹p, Ä‘á»«ng bá» lá»¡ cÆ¡ há»™i!"
    elif stats['accuracy'] >= 62:
        msg = "âœ… Cáº§u Ä‘ang á»•n Ä‘á»‹nh, cÃ³ thá»ƒ tá»± tin vÃ o tiá»n."
    elif stats['accuracy'] >= 55:
        msg = "âš ï¸ SÃ³ng dao Ä‘á»™ng, nÃªn vÃ o má»©c vá»«a pháº£i, trÃ¡nh all-in!"
    else:
        msg = "âš ï¸ SÃ³ng nhiá»…u, hÃ£y cÃ¢n nháº¯c quan sÃ¡t hoáº·c giáº£m Ä‘iá»ƒm."
    if streak >= 3 and last:
        msg += f" (Chuá»—i tháº¯ng {streak} phiÃªn!)"
    if streak >= 3 and not last:
        msg += f" (Chuá»—i thua {streak} phiÃªn, nÃªn giáº£m cÆ°á»£c hoáº·c quan sÃ¡t!)"
    if trend:
        msg += f" Xu hÆ°á»›ng: {trend}."
    if bao_warn:
        msg += " Äáº·c biá»‡t chÃº Ã½ kháº£ nÄƒng bÃ£o!"
    return msg

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ðŸ¤– Gá»­i 3 sá»‘ káº¿t quáº£ gáº§n nháº¥t Ä‘á»ƒ nháº­n dá»± Ä‘oÃ¡n (vÃ­ dá»¥: 456 hoáº·c 4 5 6). GÃµ /backup Ä‘á»ƒ xuáº¥t lá»‹ch sá»­ ra file."
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global retrain_counter
    text = update.message.text.strip()

    # Check nháº­p nháº§m, nháº­p láº·p (so vá»›i phiÃªn trÆ°á»›c)
    df_hist_check = fetch_history(1, with_actual=False)
    if df_hist_check.shape[0] > 0:
        last_input_str = df_hist_check.iloc[0]["input"]
        if re.match(r"^\d{3}$", text):
            this_input = f"{text[0]} {text[1]} {text[2]}"
        elif re.match(r"^\d+ \d+ \d+$", text):
            this_input = text
        else:
            this_input = ""
        if last_input_str == this_input:
            await update.message.reply_text("âš ï¸ Báº¡n vá»«a nháº­p káº¿t quáº£ nÃ y á»Ÿ phiÃªn trÆ°á»›c. Náº¿u nháº­p nháº§m, gá»­i láº¡i Ä‘Ãºng káº¿t quáº£ má»›i!")
            return

    # Chuáº©n hÃ³a input: '123' hoáº·c '1 2 3'
    if re.match(r"^\d{3}$", text):
        numbers = [int(x) for x in text]
        input_str = f"{numbers[0]} {numbers[1]} {numbers[2]}"
    elif re.match(r"^\d+ \d+ \d+$", text):
        numbers = [int(x) for x in text.split()]
        input_str = text
    else:
        await update.message.reply_text("âš ï¸ Vui lÃ²ng nháº­p 3 sá»‘ liá»n nhau (VD: 345) hoáº·c 3 sá»‘ cÃ¡ch nhau báº±ng dáº¥u cÃ¡ch (VD: 3 4 5).")
        return

    # GÃ¡n nhÃ£n thá»±c táº¿ cho lÆ°á»£t chÆ¡i trÆ°á»›c Ä‘Ã³ (náº¿u cÃ³)
    last_entry = None
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT id, input FROM history WHERE actual IS NULL ORDER BY id DESC LIMIT 1")
            last_entry = cur.fetchone()
    retrain_needed = False
    if last_entry:
        last_id, last_input = last_entry
        actual_label = label_func(numbers)
        with get_db_conn() as conn2:
            with conn2.cursor() as cur2:
                cur2.execute("UPDATE history SET actual = %s WHERE id = %s", (actual_label, last_id))
                conn2.commit()
        total = get_total_history_count()
        await update.message.reply_text(f"âœ… ÄÃ£ ghi nháº­n káº¿t quáº£ thá»±c táº¿ phiÃªn má»›i. Tá»•ng sá»‘ phiÃªn Ä‘Ã£ ghi nháº­n: {total}")
        retrain_counter += 1
        if retrain_counter >= RETRAIN_EVERY_N:
            retrain_needed = True
            retrain_counter = 0

    # PhÃ¡t hiá»‡n Ä‘á»•i thuáº­t toÃ¡n
    algo_changed = detect_algo_change()
    if algo_changed:
        await update.message.reply_text(
            f"âš ï¸ BOT phÃ¡t hiá»‡n tá»‰ lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng giáº£m máº¡nh! Game cÃ³ thá»ƒ Ä‘Ã£ Ä‘á»•i thuáº­t toÃ¡n. BOT sáº½ tá»± Ä‘á»™ng há»c láº¡i sÃ³ng má»›i."
        )
        retrain_needed = True
        retrain_counter = 0

    # Láº¥y cÃ¡c phiÃªn trÆ°á»›c cho feature chuá»—i
    df_hist = fetch_history(FEATURE_WINDOW-1, with_actual=False)
    prev_inputs = []
    if not df_hist.empty:
        prev_inputs = [[int(n) for n in s.split()] for s in reversed(df_hist["input"].tolist())]

    model = load_model()
    bao_model = load_bao_model()
    model_total = load_total_model()
    input_data = numbers

    # Láº¥y xÃ¡c suáº¥t tá»«ng tá»•ng tá»« model multi-class
    prob_dict = predict_total_prob(model_total, input_data, prev_inputs) if model_total else {}
    best_totals = suggest_best_totals_any(prob_dict, top_n=3) if prob_dict else []
    # Dá»± Ä‘oÃ¡n tÃ i/xá»‰u, cháºµn/láº» cá»§a tá»•ng xÃ¡c suáº¥t cao nháº¥t
    if best_totals:
        top_total = best_totals[0]
        prediction = "TÃ i" if top_total >= 11 else "Xá»‰u"
        chan_le = "Cháºµn" if top_total % 2 == 0 else "Láº»"
    else:
        top_total = sum(numbers)
        prediction = "TÃ i" if top_total >= 11 else "Xá»‰u"
        chan_le = "Cháºµn" if top_total % 2 == 0 else "Láº»"
        best_totals = [top_total]

    insert_to_db(input_str, prediction, actual=None)
    stats = calculate_stats()
    # Chuá»—i tháº¯ng/thua vÃ  trend ngáº¯n
    df_stats = fetch_history(15)
    streak, last, trend_type = get_streak_stats(df_stats, n=5)
    trend = ""
    if stats['accuracy'] >= 75:
        trend = f"SÃ³ng máº¡nh vá» {prediction}-{chan_le}."
    elif stats['accuracy'] >= 62:
        trend = f"Æ¯u tiÃªn dáº£i {prediction}-{chan_le}."
    elif stats['accuracy'] <= 55:
        trend = "SÃ³ng nhiá»…u, nÃªn cÃ¢n nháº¯c quan sÃ¡t thÃªm."

    # Dá»± bÃ¡o bÃ£o
    bao_warn = ""
    if bao_model and len(set(input_data)) != 1:
        bao_prob = predict_bao_prob(bao_model, input_data, prev_inputs)
        if bao_prob > 0.08:
            bao_warn = "âš¡ï¸ Dá»± bÃ¡o: PhiÃªn tiáº¿p theo cÃ³ kháº£ nÄƒng xuáº¥t hiá»‡n BÃƒO!"

    trend_msg = get_trend_msg(stats, streak, last, trend, bao_warn)

    response = (
        f"ðŸŽ¯ Dá»± Ä‘oÃ¡n: {prediction} - {chan_le}\n"
        f"ðŸŽ¯ Dáº£i tá»•ng nÃªn Ä‘Ã¡nh: {', '.join(map(str, best_totals))}\n"
        f"âœ”ï¸ ÄÃºng: {stats['correct']} | âŒ Sai: {stats['wrong']} | ðŸŽ¯ {stats['accuracy']}%\n"
        f"{trend_msg}"
    )
    if bao_warn and "BÃƒO" not in trend_msg:
        response += f"\n{bao_warn}"

    await update.message.reply_text(response.strip())

    # ==== RETRAIN SAU KHI ÄÃƒ TRáº¢ Lá»œI USER (náº¿u cáº§n) ====
    if retrain_needed:
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, train_and_save_model)
        await loop.run_in_executor(None, train_bao_model)
        await loop.run_in_executor(None, train_total_model)

async def backup(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000, with_actual=False)
    if df.empty:
        await update.message.reply_text("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ backup.")
        return
    now_str = datetime.now().strftime("%Y-%m-%d_%H-%M")
    path = f"/tmp/sicbo_history_backup_{now_str}.csv"
    df.to_csv(path, index=False)
    await update.message.reply_document(document=open(path, "rb"), filename=f"sicbo_history_backup_{now_str}.csv")

def calculate_stats():
    df = fetch_history(50)
    correct = sum(df['prediction'] == df['actual'])
    total = len(df)
    wrong = total - correct
    acc = round(correct / total * 100, 2) if total > 0 else 0
    return {"correct": correct, "wrong": wrong, "accuracy": acc}

def main():
    create_table()
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("backup", backup))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
