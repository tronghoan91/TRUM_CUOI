import os
import logging
import re
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neural_network import MLPClassifier
from xgboost import XGBClassifier
from joblib import dump, load
import psycopg2
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from datetime import datetime, timedelta

# --- C·∫•u h√¨nh ---
BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
MODEL_PATH = os.getenv("MODEL_PATH", "/tmp/sicbo_model.joblib")   # Chu·∫©n Render

MIN_ACCURACY = 0.5
WINDOW_SIZE = 40

logging.basicConfig(level=logging.INFO)

# --- DB ---
def get_db_conn():
    return psycopg2.connect(DATABASE_URL)

def create_table():
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS history (
                    id SERIAL PRIMARY KEY,
                    input TEXT,
                    prediction TEXT,
                    actual TEXT,
                    created_at TIMESTAMP DEFAULT NOW()
                )
            """)
            conn.commit()

def insert_to_db(numbers, prediction, actual=None):
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO history (input, prediction, actual) VALUES (%s, %s, %s)",
                (numbers, prediction, actual)
            )
            conn.commit()

def fetch_history(limit=500, with_actual=True):
    with get_db_conn() as conn:
        query = "SELECT id, input, prediction, actual, created_at FROM history"
        if with_actual:
            query += " WHERE actual IS NOT NULL"
        query += " ORDER BY id DESC LIMIT %s"
        df = pd.read_sql(query, conn, params=(limit,))
    return df

def extract_features(results):
    return [int(n) for n in results.split()]

def label_func(nums):
    total = sum(nums)
    return "T√†i" if total >= 11 else "X·ªâu"

def train_and_save_model():
    df = fetch_history(2000)
    if df.empty:
        return None
    df = df[df["actual"].notnull()]
    if len(df) < 10:
        return None
    X = np.array([extract_features(i) for i in df["input"]])
    y = df["actual"].values
    models = [
        ("rf", RandomForestClassifier(n_estimators=100)),
        ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
        ("mlp", MLPClassifier(max_iter=2000))
    ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def load_model():
    if os.path.exists(MODEL_PATH):
        return load(MODEL_PATH)
    return train_and_save_model()

def predict_with_model(model, input_data):
    X = np.array([extract_features(input_data)])
    return model.predict(X)[0]

def detect_algo_change():
    df = fetch_history(WINDOW_SIZE)
    if len(df) < WINDOW_SIZE:
        return False
    acc = sum(df['prediction'] == df['actual']) / WINDOW_SIZE
    return acc < MIN_ACCURACY

def train_with_recent_data(n=100):
    df = fetch_history(n)
    df = df[df["actual"].notnull()]
    if len(df) < 10:
        return None
    X = np.array([extract_features(i) for i in df["input"]])
    y = df["actual"].values
    models = [
        ("rf", RandomForestClassifier(n_estimators=100)),
        ("xgb", XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric="mlogloss")),
        ("mlp", MLPClassifier(max_iter=2000))
    ]
    ensemble = VotingClassifier(estimators=models, voting='hard')
    ensemble.fit(X, y)
    dump(ensemble, MODEL_PATH)
    return ensemble

def get_last_play_time():
    df = fetch_history(1, with_actual=False)
    if df.empty:
        return None
    return df["created_at"].iloc[0]

def time_diff_message(last_time):
    if last_time is None:
        return ""
    now = datetime.now(last_time.tzinfo)
    diff = now - last_time
    if diff > timedelta(hours=4):
        return ("‚ö†Ô∏è L∆∞u √Ω: ƒê√£ l√¢u b·∫°n ch∆∞a nh·∫≠p k·∫øt qu·∫£ th·ª±c t·∫ø v√†o bot. "
                "K·∫øt qu·∫£ d·ª± ƒëo√°n ch·ªâ c√≥ t√≠nh ch·∫•t tham kh·∫£o, kh√¥ng ƒë·∫£m b·∫£o ƒë√∫ng v·ªõi t·ª´ng th·ªùi ƒëi·ªÉm ho·∫∑c phi√™n ch∆°i, "
                "ƒë·∫∑c bi·ªát n·∫øu b·∫°n ch∆°i ·ªü c√°c th·ªùi ƒëi·ªÉm kh√°c nhau.")
    return ""

def generate_response(prediction, input_text, stats, time_msg):
    nums = list(map(int, input_text.split()))
    total = sum(nums)
    tai_xiu = "T√†i" if total >= 11 else "X·ªâu"
    chan_le = "Ch·∫µn" if total % 2 == 0 else "L·∫ª"
    bao = "üé≤ B√ÉO! Ba s·ªë gi·ªëng nhau!" if len(set(nums)) == 1 else ""
    response = (
        f"üéØ D·ª± ƒëo√°n: {prediction}\n"
        f"üî¢ T·ªïng: {total} ‚Üí {tai_xiu} - {chan_le}\n"
        f"{bao}\n\n"
        f"üìä Th·ªëng k√™ g·∫ßn ƒë√¢y:\n"
        f"‚úîÔ∏è ƒê√∫ng: {stats['correct']} | ‚ùå Sai: {stats['wrong']} | üéØ T·ªâ l·ªá: {stats['accuracy']}%\n"
    )
    if time_msg:
        response += "\n" + time_msg
    return response.strip()

def calculate_stats():
    df = fetch_history(50)
    correct = sum(df['prediction'] == df['actual'])
    total = len(df)
    wrong = total - correct
    acc = round(correct / total * 100, 2) if total > 0 else 0
    return {"correct": correct, "wrong": wrong, "accuracy": acc}

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ü§ñ G·ª≠i 3 s·ªë k·∫øt qu·∫£ g·∫ßn nh·∫•t ƒë·ªÉ nh·∫≠n d·ª± ƒëo√°n T√†i/X·ªâu (VD: 1 3 2).\n"
        "H√£y g·ª≠i li√™n t·ª•c k·∫øt qu·∫£ c·ªßa c√°c phi√™n ƒë·ªÉ bot t·ª± h·ªçc v√† ng√†y c√†ng ch√≠nh x√°c nh√©!"
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip()
    if not re.match(r"^\d+ \d+ \d+$", text):
        await update.message.reply_text("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë√∫ng ƒë·ªãnh d·∫°ng: 3 s·ªë c√°ch nhau b·∫±ng kho·∫£ng tr·∫Øng (VD: 1 2 3)")
        return

    # G√°n nh√£n th·ª±c t·∫ø cho l∆∞·ª£t ch∆°i tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥)
    with get_db_conn() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT id, input FROM history WHERE actual IS NULL ORDER BY id DESC LIMIT 1")
            last_entry = cur.fetchone()
    if last_entry:
        last_id, last_input = last_entry
        actual_label = label_func(extract_features(text))
        with get_db_conn() as conn2:
            with conn2.cursor() as cur2:
                cur2.execute("UPDATE history SET actual = %s WHERE id = %s", (actual_label, last_id))
                conn2.commit()
        train_and_save_model()

    # Ph√°t hi·ªán ƒë·ªïi thu·∫≠t to√°n
    algo_changed = detect_algo_change()
    if algo_changed:
        train_with_recent_data(WINDOW_SIZE * 2)
        await update.message.reply_text(
            f"‚ö†Ô∏è BOT ph√°t hi·ªán t·ªâ l·ªá d·ª± ƒëo√°n ƒë√∫ng gi·∫£m m·∫°nh! Game c√≥ th·ªÉ ƒë√£ ƒë·ªïi thu·∫≠t to√°n. "
            f"BOT s·∫Ω t·ª± ƒë·ªông h·ªçc l·∫°i d·ª±a tr√™n {WINDOW_SIZE * 2} v√°n g·∫ßn nh·∫•t ƒë·ªÉ th√≠ch ·ª©ng s√≥ng m·ªõi!"
        )

    model = load_model()
    if model is not None:
        prediction = predict_with_model(model, text)
    else:
        prediction = label_func(extract_features(text))

    insert_to_db(text, prediction, actual=None)
    stats = calculate_stats()
    time_msg = time_diff_message(get_last_play_time())
    response = generate_response(prediction, text, stats, time_msg)
    await update.message.reply_text(response)

def main():
    create_table()
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
